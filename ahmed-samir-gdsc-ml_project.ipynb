{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Ahmed Samir\n#Mostafa Abdelraheem Mostafa\n#Basmala mohamed gamal eldin\n#Team Name: AMB","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-24T13:17:56.056548Z","iopub.execute_input":"2024-06-24T13:17:56.057113Z","iopub.status.idle":"2024-06-24T13:17:56.474598Z","shell.execute_reply.started":"2024-06-24T13:17:56.057063Z","shell.execute_reply":"2024-06-24T13:17:56.473364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n\nos.environ['KAGGLE_USERNAME'] = 'ahmedsamir1598'\nos.environ['KAGGLE_KEY'] = 'a1ea546319c78fa3d825b347704b684d'","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:17:56.476737Z","iopub.execute_input":"2024-06-24T13:17:56.477230Z","iopub.status.idle":"2024-06-24T13:17:56.483655Z","shell.execute_reply.started":"2024-06-24T13:17:56.477198Z","shell.execute_reply":"2024-06-24T13:17:56.482357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!kaggle competitions download -c gdsc-ml-workshop-final-project","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:17:57.271426Z","iopub.execute_input":"2024-06-24T13:17:57.271844Z","iopub.status.idle":"2024-06-24T13:17:59.756302Z","shell.execute_reply.started":"2024-06-24T13:17:57.271814Z","shell.execute_reply":"2024-06-24T13:17:59.754980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\nimport os\n\n# Define the path to the zip file\nzip_file_path = '/kaggle/working/gdsc-ml-workshop-final-project.zip'\n\n# Define the directory to extract to\nextract_dir = '/kaggle/working/'\n\n# Ensure the directory exists\nos.makedirs(extract_dir, exist_ok=True)\n\n# Extract the zip file\nwith zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n    zip_ref.extractall(extract_dir)\n\nprint(\"Extraction completed!\")","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:18:01.767626Z","iopub.execute_input":"2024-06-24T13:18:01.768135Z","iopub.status.idle":"2024-06-24T13:18:02.712688Z","shell.execute_reply.started":"2024-06-24T13:18:01.768097Z","shell.execute_reply":"2024-06-24T13:18:02.711448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/working/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/working/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:18:03.861221Z","iopub.execute_input":"2024-06-24T13:18:03.862272Z","iopub.status.idle":"2024-06-24T13:18:05.681397Z","shell.execute_reply.started":"2024-06-24T13:18:03.862231Z","shell.execute_reply":"2024-06-24T13:18:05.679977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.info())\nprint(train_df.describe())\nprint(train_df.isnull())","metadata":{"execution":{"iopub.status.busy":"2024-06-22T18:09:07.283888Z","iopub.execute_input":"2024-06-22T18:09:07.284727Z","iopub.status.idle":"2024-06-22T18:09:07.363122Z","shell.execute_reply.started":"2024-06-22T18:09:07.284677Z","shell.execute_reply":"2024-06-22T18:09:07.361777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_df.info())\nprint(test_df.describe())\nprint(test_df.isnull())","metadata":{"execution":{"iopub.status.busy":"2024-06-22T18:09:18.336956Z","iopub.execute_input":"2024-06-22T18:09:18.337435Z","iopub.status.idle":"2024-06-22T18:09:18.368665Z","shell.execute_reply.started":"2024-06-22T18:09:18.337397Z","shell.execute_reply":"2024-06-22T18:09:18.367319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.dropna()","metadata":{"execution":{"iopub.status.busy":"2024-06-22T18:09:40.813805Z","iopub.execute_input":"2024-06-22T18:09:40.814492Z","iopub.status.idle":"2024-06-22T18:09:40.854290Z","shell.execute_reply.started":"2024-06-22T18:09:40.814431Z","shell.execute_reply":"2024-06-22T18:09:40.852934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nsns.set_style('whitegrid')","metadata":{"execution":{"iopub.status.busy":"2024-06-22T15:33:36.123498Z","iopub.execute_input":"2024-06-22T15:33:36.123850Z","iopub.status.idle":"2024-06-22T15:33:36.791174Z","shell.execute_reply.started":"2024-06-22T15:33:36.123797Z","shell.execute_reply":"2024-06-22T15:33:36.789946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T15:33:36.795580Z","iopub.execute_input":"2024-06-22T15:33:36.796299Z","iopub.status.idle":"2024-06-22T15:33:36.807944Z","shell.execute_reply.started":"2024-06-22T15:33:36.796264Z","shell.execute_reply":"2024-06-22T15:33:36.806285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df['subject'].unique())\nprint(train_df['subject'].nunique())","metadata":{"execution":{"iopub.status.busy":"2024-06-22T15:33:36.809481Z","iopub.execute_input":"2024-06-22T15:33:36.809884Z","iopub.status.idle":"2024-06-22T15:33:36.830084Z","shell.execute_reply.started":"2024-06-22T15:33:36.809852Z","shell.execute_reply":"2024-06-22T15:33:36.828817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***It would be better to reduce the num of categories in subject, and try feature engineerning by adding another feature \"Region\" that will include \"worldnews\", \"US_News\", \"Middle-east\".***","metadata":{}},{"cell_type":"code","source":"train_df['subject'] = train_df['subject'].apply(lambda x: 'politics' if x == 'politicsNews' else x)\n\n# Verify the changes\nprint(train_df['subject'].value_counts())\nprint(train_df['subject'].nunique())","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:18:09.633491Z","iopub.execute_input":"2024-06-24T13:18:09.634825Z","iopub.status.idle":"2024-06-24T13:18:09.685067Z","shell.execute_reply.started":"2024-06-24T13:18:09.634783Z","shell.execute_reply":"2024-06-24T13:18:09.683373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"common_classes = [\n    'politics', 'worldnews', 'News', 'left-news', \n    'Government News', 'US_News', 'Middle-east'\n]\n\n# Function to classify subjects\ndef classify_subject(subject):\n    if subject in common_classes:\n        return subject\n    else:\n        return 'longnews'\n\n# Apply the classification function to create a new column\ntrain_df['subject_class'] = train_df['subject'].apply(classify_subject)\nprint(train_df['subject_class'].value_counts())\nprint(train_df['subject_class'].nunique())\n","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:22:18.871434Z","iopub.execute_input":"2024-06-24T13:22:18.872523Z","iopub.status.idle":"2024-06-24T13:22:18.919365Z","shell.execute_reply.started":"2024-06-24T13:22:18.872472Z","shell.execute_reply":"2024-06-24T13:22:18.918152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Something is suspicious about worldnews as a subject. I believe it might contain also be categorizing data for US and Middle east.","metadata":{}},{"cell_type":"markdown","source":"Found entry with such idea\n\n9540 ISMAILIA,Egypt (Reuters) - At least 24 militants and six soldiers were killed on Sunday in attacks o...\nworldnews\n\n9658\nA house divided: How Saudi Crown Prince purged royal family rivals\nBEIRUT/RIYADH (Reuters) - The first hint that something was amiss came in a letter. On Saturday Nov....\nworldnews\n\n40398\nU.S. judge rejects bid to dismiss Indonesian immigrant's lawsuit\nBOSTON (Reuters) - A federal judge on Wednesday declined to dismiss a lawsuit by an Indonesian illeg...\nworldnews","metadata":{}},{"cell_type":"code","source":"train_df.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:25:30.585346Z","iopub.execute_input":"2024-06-24T13:25:30.585776Z","iopub.status.idle":"2024-06-24T13:25:30.639272Z","shell.execute_reply.started":"2024-06-24T13:25:30.585714Z","shell.execute_reply":"2024-06-24T13:25:30.637895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def assign_region(title):\n    title_lower = title.lower()\n    if any(keyword in title_lower for keyword in ['egypt', 'saudi', 'middle_east', 'iraq', 'palestine', 'iran', 'jordan', 'yemen', 'uae', 'qatar', 'lebanon', 'israel', 'kuwait','oman', 'syria', 'bahrain', 't√ºrkiye', 'cyprus', 'cairo','kurds','mena' ]):\n        return 'Middle_East'\n    elif any(keyword in title_lower for keyword in ['us', 'u.s.', 'united states']):\n        return 'US'\n    elif any(keyword in title_lower for keyword in ['swiss', 'switzerland','croatia', 'germany','berlin', 'france', 'italy', 'spain', 'uk', 'united kingdom', ]):\n        return 'Europe'\n    elif any(keyword in title_lower for keyword in ['china', 'japan', 'korea','myanmar','rohingya','india','russia']):\n        return 'Asia'\n    elif any(keyword in title_lower for keyword in ['nigeria', 'kenya', 'south africa','cameroon','sudan','ethiopia','somalia']):\n        return 'Africa'\n    elif any(keyword in title_lower for keyword in ['brazil', 'argentina', 'colombia']):\n        return 'South_America'\n    elif any(keyword in title_lower for keyword in ['zealand', 'australia','nz']):\n        return 'Australia'\n\n    else:\n        return 'WorldNews'\n\n# Assuming df_no_duplicates_text_and_title is your DataFrame\ntrain_df['region'] = train_df['title'].apply(assign_region)\nprint(train_df)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:27:33.289831Z","iopub.execute_input":"2024-06-24T13:27:33.290603Z","iopub.status.idle":"2024-06-24T13:27:33.845222Z","shell.execute_reply.started":"2024-06-24T13:27:33.290567Z","shell.execute_reply":"2024-06-24T13:27:33.843987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df['region'].value_counts())\nprint(train_df['region'].nunique())","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:27:40.696082Z","iopub.execute_input":"2024-06-24T13:27:40.697233Z","iopub.status.idle":"2024-06-24T13:27:40.715617Z","shell.execute_reply.started":"2024-06-24T13:27:40.697191Z","shell.execute_reply":"2024-06-24T13:27:40.714115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df['date'])","metadata":{"execution":{"iopub.status.busy":"2024-06-22T18:11:34.811151Z","iopub.execute_input":"2024-06-22T18:11:34.811630Z","iopub.status.idle":"2024-06-22T18:11:34.820583Z","shell.execute_reply.started":"2024-06-22T18:11:34.811594Z","shell.execute_reply":"2024-06-22T18:11:34.819196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def safe_to_datetime(date):\n    try:\n        return pd.to_datetime(date, errors='raise')\n    except Exception as e:\n        print(f\"Date parsing error for date '{date}': {e}\")\n        return pd.NaT\n\n# Apply date parsing with error handling\ntrain_df['date'] = train_df['date'].apply(safe_to_datetime)\n\n# Drop rows where date parsing failed (i.e., date is NaT)\n#df_no_duplicates_text_and_title.dropna(subset=['date'], inplace=True)\n\n# Define date ranges\ndate_ranges = [\n    (pd.Timestamp('2015-03-31'), pd.Timestamp('2015-05-22')),\n    (pd.Timestamp('2015-05-22'), pd.Timestamp('2015-07-14')),\n    (pd.Timestamp('2015-07-14'), pd.Timestamp('2015-09-05')),\n    (pd.Timestamp('2015-09-05'), pd.Timestamp('2015-12-20')),\n    (pd.Timestamp('2015-12-20'), pd.Timestamp('2016-02-10')),\n    (pd.Timestamp('2016-02-10'), pd.Timestamp('2016-04-03')),\n    (pd.Timestamp('2016-04-03'), pd.Timestamp('2016-05-26')),\n    (pd.Timestamp('2016-05-26'), pd.Timestamp('2016-07-18')),\n    (pd.Timestamp('2016-07-18'), pd.Timestamp('2016-09-09')),\n    (pd.Timestamp('2016-09-09'), pd.Timestamp('2016-10-31')),\n    (pd.Timestamp('2016-10-31'), pd.Timestamp('2016-12-12')),\n    (pd.Timestamp('2016-12-12'), pd.Timestamp('2017-02-14')),\n    (pd.Timestamp('2017-02-14'), pd.Timestamp('2017-04-08')),\n    (pd.Timestamp('2017-04-08'), pd.Timestamp('2017-05-31')),\n    (pd.Timestamp('2017-05-31'), pd.Timestamp('2017-07-22')),\n    (pd.Timestamp('2017-07-22'), pd.Timestamp('2017-09-13')),\n    (pd.Timestamp('2017-09-13'), pd.Timestamp('2017-11-05')),\n    (pd.Timestamp('2017-11-05'), pd.Timestamp('2017-12-28')),\n    (pd.Timestamp('2017-12-28'), pd.Timestamp('2018-02-19'))\n]\n\n# Function to assign date range\ndef assign_date_range(date):\n    for i, (start, end) in enumerate(date_ranges):\n        if start <= date <= end:\n            return f'Range_{i+1}'\n    return 'ŸåRange_0'\n\n# Apply function to create new column\ntrain_df['date_range'] = train_df['date'].apply(assign_date_range)\n\n# Print the result\nprint(train_df[['date', 'date_range']])","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:27:58.290491Z","iopub.execute_input":"2024-06-24T13:27:58.290892Z","iopub.status.idle":"2024-06-24T13:28:20.504188Z","shell.execute_reply.started":"2024-06-24T13:27:58.290860Z","shell.execute_reply":"2024-06-24T13:28:20.502963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df['date_range'].value_counts())\nprint(train_df['date_range'].nunique())","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:28:30.967102Z","iopub.execute_input":"2024-06-24T13:28:30.967978Z","iopub.status.idle":"2024-06-24T13:28:30.992866Z","shell.execute_reply.started":"2024-06-24T13:28:30.967924Z","shell.execute_reply":"2024-06-24T13:28:30.991238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.to_csv('output.csv', index=False)\nprint(\"DataFrame has been saved to 'output.csv'\")","metadata":{"execution":{"iopub.status.busy":"2024-06-22T15:33:55.159812Z","iopub.execute_input":"2024-06-22T15:33:55.160226Z","iopub.status.idle":"2024-06-22T15:33:59.740955Z","shell.execute_reply.started":"2024-06-22T15:33:55.160192Z","shell.execute_reply":"2024-06-22T15:33:59.739456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install spacy\n!python -m spacy download en_core_web_sm\n","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:28:37.928259Z","iopub.execute_input":"2024-06-24T13:28:37.929082Z","iopub.status.idle":"2024-06-24T13:29:16.288964Z","shell.execute_reply.started":"2024-06-24T13:28:37.929031Z","shell.execute_reply":"2024-06-24T13:29:16.287395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['cleaned_text'] = df_no_duplicates_text_and_title['cleaned_text']\ntrain_df['cleaned_title']= df_no_duplicates_text_and_title['cleaned_title']","metadata":{"execution":{"iopub.status.busy":"2024-06-22T18:17:27.837725Z","iopub.execute_input":"2024-06-22T18:17:27.838249Z","iopub.status.idle":"2024-06-22T18:17:27.855059Z","shell.execute_reply.started":"2024-06-22T18:17:27.838209Z","shell.execute_reply":"2024-06-22T18:17:27.853562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-06-22T18:17:41.412355Z","iopub.execute_input":"2024-06-22T18:17:41.412843Z","iopub.status.idle":"2024-06-22T18:17:41.429081Z","shell.execute_reply.started":"2024-06-22T18:17:41.412792Z","shell.execute_reply":"2024-06-22T18:17:41.427201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import spacy\nfrom spacy.lang.en.stop_words import STOP_WORDS\n\nnlp = spacy.load('en_core_web_sm')\ndef preprocess(text):\n    # Apply the spaCy model to the text\n    doc = nlp(text)\n    \n    # Remove stop words and punctuation, and lemmatize the words\n    words = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n    \n    return ' '.join(words)\ntrain_df['cleaned_text'] = train_df['text'].apply(preprocess)\ntrain_df['cleaned_title'] = train_df['title'].apply(preprocess)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:34:30.770379Z","iopub.execute_input":"2024-06-24T13:34:30.770781Z","iopub.status.idle":"2024-06-24T14:40:54.399305Z","shell.execute_reply.started":"2024-06-24T13:34:30.770751Z","shell.execute_reply":"2024-06-24T14:40:54.397659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.to_csv('tokenized.csv', index=False)\nprint(\"DataFrame has been saved to 'tokenized.csv'\")","metadata":{"execution":{"iopub.status.busy":"2024-06-22T16:38:43.131467Z","iopub.execute_input":"2024-06-22T16:38:43.132225Z","iopub.status.idle":"2024-06-22T16:38:50.477245Z","shell.execute_reply.started":"2024-06-22T16:38:43.132182Z","shell.execute_reply":"2024-06-22T16:38:50.475939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = train_df\ndf['combined'] = df['cleaned_title'] + ' ' + df['cleaned_text']\ndf['combined']=df['combined'].astype(str)\nfrom sklearn.model_selection import train_test_split\nfeatures = ['combined','date_range', 'subject_class', 'region']\nX = df[features]\ny = df['class']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\nprint(f'X_train shape after splitting: {X_train.shape}')\nprint(f'y_train shape after splitting: {len(y_train)}')\nprint(f'X_test shape after splitting: {X_test.shape}')\nprint(f'y_test shape after splitting: {len(y_test)}')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-24T14:40:54.401676Z","iopub.execute_input":"2024-06-24T14:40:54.402200Z","iopub.status.idle":"2024-06-24T14:40:55.145817Z","shell.execute_reply.started":"2024-06-24T14:40:54.402159Z","shell.execute_reply":"2024-06-24T14:40:55.144536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Define the columns to be used for different transformations\ntext_col = 'combined'\nother_cols = ['date_range', 'subject_class', 'region']\n\n# Define the preprocessing steps for different columns\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('text', TfidfVectorizer(max_features=5000), text_col),\n        ('other', OneHotEncoder(), other_cols)\n    ],\n    remainder='passthrough'\n)\n\n# Define the model pipeline\nmodel = Pipeline([\n    ('preprocessor', preprocessor),\n    ('classifier', LogisticRegression())\n])\n\n# Fit the model\nmodel.fit(X_train, y_train)\n\n# Predict and evaluate\ny_pred = model.predict(X_test)\n\nprint('Accuracy:', accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-24T14:40:55.147666Z","iopub.execute_input":"2024-06-24T14:40:55.148195Z","iopub.status.idle":"2024-06-24T14:41:11.276361Z","shell.execute_reply.started":"2024-06-24T14:40:55.148163Z","shell.execute_reply":"2024-06-24T14:41:11.275100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbc = Pipeline([\n    ('preprocessor', preprocessor),\n    ('classifier', GradientBoostingClassifier(n_estimators=100, random_state=42))\n])\ngbc.fit(X_train, y_train)\ny_gbc_pred = gbc.predict(X_test)\naccuracy_gbc = accuracy_score(y_test, y_gbc_pred)\nprint(f\"Model Accuracy: {accuracy_gbc:.2f}\")\nprint(classification_report(y_test, y_gbc_pred))","metadata":{"execution":{"iopub.status.busy":"2024-06-24T14:41:11.279493Z","iopub.execute_input":"2024-06-24T14:41:11.280325Z","iopub.status.idle":"2024-06-24T14:45:07.715085Z","shell.execute_reply.started":"2024-06-24T14:41:11.280281Z","shell.execute_reply":"2024-06-24T14:45:07.713904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgbc = Pipeline([\n    ('preprocessor', preprocessor),\n    ('classifier', XGBClassifier(n_estimators=100, random_state=42))\n])\nxgbc.fit(X_train, y_train)\ny_xgbc_pred = xgbc.predict(X_test)\naccuracy_xgbc = accuracy_score(y_test, y_xgbc_pred)\nprint(f\"Model Accuracy: {accuracy_xgbc:.2f}\")\nprint(classification_report(y_test, y_xgbc_pred))","metadata":{"execution":{"iopub.status.busy":"2024-06-24T14:45:07.716539Z","iopub.execute_input":"2024-06-24T14:45:07.716919Z","iopub.status.idle":"2024-06-24T14:45:44.430555Z","shell.execute_reply.started":"2024-06-24T14:45:07.716872Z","shell.execute_reply":"2024-06-24T14:45:44.429304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier, StackingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import accuracy_score\nestimators = [\n    ('gb', make_pipeline(StandardScaler(), GradientBoostingClassifier(n_estimators=100,random_state=42))),\n    ('xgb', make_pipeline(StandardScaler(), XGBClassifier(n_estimators=100, random_state=42)))\n]\n\n# Define stacking classifier with Logistic Regression as the meta-classifier\nstacking_model = Pipeline([\n    ('preprocessor', preprocessor),\n    ('classifier', StackingClassifier(\n    estimators=estimators,\n    final_estimator=LogisticRegression(),\n    passthrough=False,  # If passthrough=True, the original features are added to the meta-classifier\n    cv=5  # Number of cross-validation folds\n))\n])\n\n# Fit the stacking model\nstacking_model.fit(X_train, y_train)\n\n# Predict using the stacking model\nstacking_preds = stacking_model.predict(X_test)\n\n# Evaluate the model\nprint(\"Stacking Classifier Accuracy:\", accuracy_score(y_test, stacking_preds))\nprint(classification_report(y_test, stacking_preds))","metadata":{"execution":{"iopub.status.busy":"2024-06-24T14:45:44.432358Z","iopub.execute_input":"2024-06-24T14:45:44.432709Z","iopub.status.idle":"2024-06-24T14:45:44.555605Z","shell.execute_reply.started":"2024-06-24T14:45:44.432681Z","shell.execute_reply":"2024-06-24T14:45:44.554252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Assuming `test.csv` contains your test data\ntest_df = pd.read_csv(\"/kaggle/working/test.csv\")\ntest_df['subject'] = test_df['subject'].apply(lambda x: 'politics' if x == 'politicsNews' else x)\ntest_df['region'] = test_df['title'].apply(assign_region)\ntest_df['date'] = test_df['date'].apply(safe_to_datetime)\ntest_df['date_range'] = test_df['date'].apply(assign_date_range)\ntest_df['cleaned_text'] = test_df['text'].apply(preprocess)\ntest_df['cleaned_title'] = test_df['title'].apply(preprocess)\ntest_df['combined'] = test_df['cleaned_title'] + ' ' + test_df['cleaned_text']\ntest_df['subject_class'] = test_df['subject'].apply(classify_subject)\nfeatures = ['combined','date_range', 'subject_class', 'region']\nX_test_test = test_df[features]\ny_pred = model.predict(X_test_test)\ny_gbc_pred = gbc.predict(X_test_test)\ny_xgbc_pred = xgbc.predict(X_test_test)\n# Print the predictions\n#print(y_pred)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-24T14:57:31.174463Z","iopub.execute_input":"2024-06-24T14:57:31.174885Z","iopub.status.idle":"2024-06-24T15:04:22.418543Z","shell.execute_reply.started":"2024-06-24T14:57:31.174853Z","shell.execute_reply":"2024-06-24T15:04:22.417247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_lr = 0\ncount_gbc = 0\ncount_xgb = 0\ncount_stacking = 0\nfor i in y_pred:\n    if i == 0:\n        count_lr+=1\nfor i in y_gbc_pred:\n    if i == 0:\n        count_gbc+=1\nfor i in y_xgbc_pred:\n    if i == 0:\n        count_xgb+=1\n#for i in stacking_preds:\n#    if i == 0:\n#        count_stacking+=1\nprint(f\"count0 LR:{count_lr}\")\nprint(f\"count0 count_gbc:{count_gbc}\")\nprint(f\"count0 count_xgb:{count_xgb}\")\n#print(f\"count0 count_stacking:{count_stacking}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-24T15:04:22.420767Z","iopub.execute_input":"2024-06-24T15:04:22.421305Z","iopub.status.idle":"2024-06-24T15:04:22.436635Z","shell.execute_reply.started":"2024-06-24T15:04:22.421260Z","shell.execute_reply":"2024-06-24T15:04:22.435255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_lr = 0\ncount_gbc = 0\ncount_xgb = 0\ncount_stacking = 0\nfor i in y_pred:\n    if i == 1:\n        count_lr+=1\nfor i in y_gbc_pred:\n    if i == 1:\n        count_gbc+=1\nfor i in y_xgbc_pred:\n    if i == 1:\n        count_xgb+=1\n#for i in stacking_preds:\n#    if i == 1:\n#        count_stacking+=1\nprint(f\"count1 LR:{count_lr}\")\nprint(f\"count1 count_gbc:{count_gbc}\")\nprint(f\"count1 count_xgb:{count_xgb}\")\n#print(f\"count1 count_stacking:{count_stacking}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-24T15:04:54.630669Z","iopub.execute_input":"2024-06-24T15:04:54.631096Z","iopub.status.idle":"2024-06-24T15:04:54.645595Z","shell.execute_reply.started":"2024-06-24T15:04:54.631063Z","shell.execute_reply":"2024-06-24T15:04:54.644401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_df = pd.DataFrame({'ID': test_df['ID'], 'TARGET': y_xgbc_pred})\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv('predictions.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T15:07:05.555416Z","iopub.execute_input":"2024-06-24T15:07:05.555846Z","iopub.status.idle":"2024-06-24T15:07:05.573493Z","shell.execute_reply.started":"2024-06-24T15:07:05.555813Z","shell.execute_reply":"2024-06-24T15:07:05.572288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_df = pd.DataFrame({'ID': test_df['ID'], 'TARGET': y_gbc_pred})\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv('predictions_gbc.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T15:17:47.545327Z","iopub.execute_input":"2024-06-24T15:17:47.545765Z","iopub.status.idle":"2024-06-24T15:17:47.563312Z","shell.execute_reply.started":"2024-06-24T15:17:47.545730Z","shell.execute_reply":"2024-06-24T15:17:47.562015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = pd.read_csv(\"/kaggle/working/predictions.csv\")\nprint(predictions)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T18:55:24.143064Z","iopub.execute_input":"2024-06-22T18:55:24.143610Z","iopub.status.idle":"2024-06-22T18:55:24.159430Z","shell.execute_reply.started":"2024-06-22T18:55:24.143568Z","shell.execute_reply":"2024-06-22T18:55:24.157967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}